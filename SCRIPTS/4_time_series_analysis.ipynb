{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6M12a1VnxgI2H4SHeBwHa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t-aridi/DS-4002/blob/main/SCRIPTS/4_time_series_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xed3EBb1YG7o",
        "outputId": "30098dfe-78a4-45f3-b542-f493d407c70d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.0.2)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.14.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
            "Collecting pmdarima\n",
            "  Downloading pmdarima-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (1.4.2)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (1.14.1)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (0.14.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (2.3.0)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (75.1.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pmdarima) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pmdarima) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pmdarima) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22->pmdarima) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.2->pmdarima) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19->pmdarima) (1.17.0)\n",
            "Downloading pmdarima-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pmdarima\n",
            "Successfully installed pmdarima-2.0.4\n",
            "Requirement already satisfied: prophet in /usr/local/lib/python3.11/dist-packages (1.1.6)\n",
            "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from prophet) (1.2.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.11/dist-packages (from prophet) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from prophet) (3.10.0)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from prophet) (2.2.2)\n",
            "Requirement already satisfied: holidays<1,>=0.25 in /usr/local/lib/python3.11/dist-packages (from prophet) (0.69)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.11/dist-packages (from prophet) (4.67.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from prophet) (6.5.2)\n",
            "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from holidays<1,>=0.25->prophet) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.4->prophet) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.4->prophet) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.17.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install statsmodels\n",
        "!pip install pmdarima\n",
        "!pip install prophet\n",
        "!apt-get install git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git clone https://github.com/ArjunaBazaz/Presidential_Approval_Rating_Prediction.git\n",
        "\n",
        "import os\n",
        "os.chdir('Presidential_Approval_Rating_Prediction/DATA')\n",
        "\n",
        "\n",
        "import glob\n",
        "\n",
        "csv_files = glob.glob('*.csv')\n",
        "print(csv_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0HadEopaj1I",
        "outputId": "59041a56-3833-4bf6-d4f2-1cdd0a7b6a47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Presidential_Approval_Rating_Prediction'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 139 (delta 45), reused 58 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (139/139), 2.38 MiB | 11.38 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n",
            "['approval_rating_obama_1_2.csv', 'approval_rating_reagan_1_2_updated.csv', 'approval_rating_clinton_1_2_updated.csv', 'approval_rating_carter_1.csv', 'approval_rating_johnson_1_2_updated.csv', 'approval_rating_bushjr_1_2_updated.csv', 'approval_rating_carter_1_updated.csv', 'approval_rating_truman_1_updated.csv', 'real_GDP_per_capita_daily_change.csv', 'approval_rating_roosevelt_3_4.csv', 'approval_rating_kennedy_1.csv', 'approval_rating_eisenhower_1_2_updated.csv', 'approval_rating_truman_1.csv', 'approval_rating_bushjr_1_2.csv', 'approval_rating_obama_1_2_updated.csv', 'approval_rating_bushsr_1.csv', 'approval_rating_nixon_1_2.csv', 'approval_rating_trump_1.csv', 'median_household_income.csv', 'approval_rating_biden_1_updated.csv', 'sp500_historical_data.csv', 'approval_rating_roosevelt_3_4_updated.csv', 'approval_rating_trump_1_updated.csv', 'approval_rating_ford_1.csv', 'unemployment_rate.csv', 'approval_rating_nixon_1_2_updated.csv', 'approval_rating_biden_1.csv', 'approval_rating_kennedy_1_updated.csv', 'approval_rating_eisenhower_1_2.csv', 'approval_rating_clinton_1_2.csv', 'approval_rating_bushsr_1_updated.csv', 'approval_rating_johnson_1_2.csv', 'real_GDP_per_capita.csv', 'approval_rating.csv', 'sp500_daily_change.csv', 'median_household_income_daily_change.csv', 'approval_rating_ford_1_updated.csv', 'approval_rating_reagan_1_2.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have imported the data we need from Github. Let's properly load our data and define a start and end date."
      ],
      "metadata": {
        "id": "4ZgVG3isb54k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# -------------------------\n",
        "# 1. Load Datasets and Parse Dates\n",
        "# -------------------------\n",
        "\n",
        "# Load the approval ratings dataset and convert dates (handle mixed formats)\n",
        "approval_df = pd.read_csv('approval_rating.csv', parse_dates=['Start Date', 'End Date'])\n",
        "approval_df['Start Date'] = pd.to_datetime(approval_df['Start Date'], errors='coerce')\n",
        "approval_df['End Date'] = pd.to_datetime(approval_df['End Date'], errors='coerce')\n",
        "\n",
        "# Load other datasets with their date columns\n",
        "income_df = pd.read_csv('median_household_income_daily_change.csv', parse_dates=['observation_date'])\n",
        "gdp_df = pd.read_csv('real_GDP_per_capita_daily_change.csv', parse_dates=['observation_date'])\n",
        "sp500_df = pd.read_csv(\n",
        "    'sp500_daily_change.csv',\n",
        "    parse_dates=['Date'],\n",
        "    date_parser=lambda x: pd.to_datetime(x, utc=True)\n",
        ")\n",
        "# Convert S&P 500 timestamps to tz-naive\n",
        "sp500_df['Date'] = sp500_df['Date'].dt.tz_convert(None)\n",
        "unemployment_df = pd.read_csv('unemployment_rate.csv', parse_dates=['observation_date'])\n",
        "\n",
        "# -------------------------\n",
        "# 2. Define the Common Date Range\n",
        "# -------------------------\n",
        "common_start = pd.Timestamp('1985-01-01')\n",
        "common_end = pd.Timestamp('2023-01-01')\n",
        "\n",
        "# It is best to restrict approval data to polls fully within the common period.\n",
        "approval_df = approval_df[(approval_df['Start Date'] >= common_start) & (approval_df['End Date'] <= common_end)]\n",
        "\n",
        "# -------------------------\n",
        "# 3. Compute Weekly Weighted Approval Rating\n",
        "# -------------------------\n",
        "# Instead of expanding by week (which can misrepresent short polls), we compute,\n",
        "# for each weekly bucket, the weighted average approval where weight equals the proportion\n",
        "# of days in the poll period that fall within the week.\n",
        "\n",
        "# Create a weekly index; here we choose weeks starting on Monday.\n",
        "weekly_index = pd.date_range(start=common_start, end=common_end, freq='W-MON')\n",
        "weekly_ratings = []  # to store computed weekly approval ratings\n",
        "\n",
        "def get_overlap_days(poll_start, poll_end, week_start, week_end):\n",
        "    # Compute the number of days overlap between poll period and the current week\n",
        "    latest_start = max(poll_start, week_start)\n",
        "    earliest_end = min(poll_end, week_end)\n",
        "    delta = (earliest_end - latest_start).days + 1  # include both endpoints\n",
        "    return max(0, delta)\n",
        "\n",
        "# Iterate over each week and compute the weighted average approval rating\n",
        "for week_start in weekly_index:\n",
        "    week_end = week_start + pd.Timedelta(days=6)\n",
        "    numerator = 0.0\n",
        "    denominator = 0.0\n",
        "    # For every poll, compute overlap with the current week\n",
        "    for _, row in approval_df.iterrows():\n",
        "        poll_start = row['Start Date']\n",
        "        poll_end = row['End Date']\n",
        "        # Skip polls that do not overlap with the week\n",
        "        if poll_end < week_start or poll_start > week_end:\n",
        "            continue\n",
        "        overlap = get_overlap_days(poll_start, poll_end, week_start, week_end)\n",
        "        if overlap <= 0:\n",
        "            continue\n",
        "        # Total duration of the poll in days (include both start and end)\n",
        "        duration = (poll_end - poll_start).days + 1\n",
        "        weight = overlap / duration\n",
        "        numerator += weight * row['Approving']\n",
        "        denominator += weight\n",
        "    # If any poll contributed, calculate weighted average; else, leave as missing (None)\n",
        "    week_rating = numerator / denominator if denominator > 0 else None\n",
        "    weekly_ratings.append(week_rating)\n",
        "\n",
        "# Create a Series for weekly approval ratings\n",
        "approval_weekly = pd.Series(weekly_ratings, index=weekly_index, name='Approval_Rating')\n",
        "\n",
        "# -------------------------\n",
        "# 4. Resample and Process the Economic Datasets\n",
        "# -------------------------\n",
        "# For consistency, we resample these to weekly frequency, aligning on our W-MON index.\n",
        "\n",
        "# S&P 500: Daily data → weekly average\n",
        "sp500_weekly = sp500_df.set_index('Date')['Close_Change'].resample('W-MON').mean()\n",
        "\n",
        "# GDP: Quarterly data → weekly via forward fill\n",
        "gdp_weekly = gdp_df.set_index('observation_date')['Change'].resample('W-MON').ffill()\n",
        "\n",
        "# Income: Annual data → weekly by linear interpolation\n",
        "income_weekly = income_df.set_index('observation_date')['Change'].resample('W-MON').interpolate(method='linear')\n",
        "\n",
        "# Unemployment: Monthly data → weekly via forward fill\n",
        "unemployment_weekly = unemployment_df.set_index('observation_date')['UNRATE'].resample('W-MON').ffill()\n",
        "\n",
        "# -------------------------\n",
        "# 5. Merge the Datasets into a Single DataFrame\n",
        "# -------------------------\n",
        "merged_df = approval_weekly.to_frame().merge(\n",
        "    sp500_weekly, left_index=True, right_index=True, how='left'\n",
        ").merge(\n",
        "    gdp_weekly, left_index=True, right_index=True, how='left'\n",
        ").merge(\n",
        "    income_weekly, left_index=True, right_index=True, how='left'\n",
        ").merge(\n",
        "    unemployment_weekly, left_index=True, right_index=True, how='left'\n",
        ")\n",
        "\n",
        "merged_df.columns = ['Approval_Rating', 'SP500_Change', 'GDP_Change', 'Income_Change', 'Unemployment_Rate']\n",
        "\n",
        "# -------------------------\n",
        "# 6. Handle Any Remaining Missing Data\n",
        "# -------------------------\n",
        "# Print missing value counts before filling:\n",
        "print(\"Missing Values Before Handling:\")\n",
        "print(merged_df.isnull().sum())\n",
        "\n",
        "# For polls, if a week has no poll data, you may want to interpolate using time-aware interpolation.\n",
        "merged_df['Approval_Rating'] = merged_df['Approval_Rating'].interpolate(method='time', limit=4)\n",
        "# For any remaining gaps, fill forward then backward for approval ratings.\n",
        "merged_df['Approval_Rating'] = merged_df['Approval_Rating'].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "# For economic indicators, fill missing values similarly.\n",
        "merged_df[['SP500_Change', 'GDP_Change', 'Income_Change', 'Unemployment_Rate']] = merged_df[\n",
        "    ['SP500_Change', 'GDP_Change', 'Income_Change', 'Unemployment_Rate']\n",
        "].ffill().bfill()\n",
        "\n",
        "print(\"\\nMissing Values After Handling:\")\n",
        "print(merged_df.isnull().sum())\n",
        "\n",
        "# merged_df now contains a complete, weekly time series ready for time series analysis.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E-mmBPjb82G",
        "outputId": "2fb3c52d-48df-42f5-8f8e-947f064f5514"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-da841af4edf8>:15: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
            "  sp500_df = pd.read_csv(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values Before Handling:\n",
            "Approval_Rating      598\n",
            "SP500_Change           0\n",
            "GDP_Change             0\n",
            "Income_Change        260\n",
            "Unemployment_Rate      0\n",
            "dtype: int64\n",
            "\n",
            "Missing Values After Handling:\n",
            "Approval_Rating      0\n",
            "SP500_Change         0\n",
            "GDP_Change           0\n",
            "Income_Change        0\n",
            "Unemployment_Rate    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-da841af4edf8>:120: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  merged_df['Approval_Rating'] = merged_df['Approval_Rating'].fillna(method='ffill').fillna(method='bfill')\n"
          ]
        }
      ]
    }
  ]
}